# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

appName: lungo-exchange
appVersion: v1
replicaCount: 1
environment:

image:
  repository: ghcr.io/agntcy/coffee-agntcy/lungo-exchange
  tag: latest
  pullPolicy: Always
  pullSecret:

service:
  port: 8000

config:
  azureOpenAiEndpoint:
  azureOpenAiDeployment:
  azureOpenAiApiVersion:
  llmProvider:
  transportServerEndpoint:
  defaultMessageTransport:
  otlpHttpEndpoint:
  identityApiServerUrl:
  # azureOpenAiEndpoint: "${AZURE_OPENAI_ENDPOINT}"
  # azureOpenAiDeployment: "${AZURE_OPENAI_DEPLOYMENT}"
  # azureOpenAiApiVersion: "${AZURE_OPENAI_API_VERSION}"
  # llmProvider: "${LLM_PROVIDER}"
  # transportServerEndpoint: "nats://nats:4222"
  # defaultMessageTransport: "NATS"
  # otlpHttpEndpoint: "http://opentelemetry-collector:4318"
  # identityApiServerUrl: "https://api.agent-identity.outshift.com"
#  llmStreaming: False

# You can use your own config here for service account
# serviceaccount:
#   annotations:
#     eks.amazonaws.com/role-arn: REPLACE_WITH_ROLE_ARN

# You can use your own ingress stack of operators and letsencrypt mechanism
ingress:
  enabled: false  # If set to true, configure the values below for your ingress setup
  name: ""
  className: ""
  host: ""
  serviceName: ""
  servicePort: ""
  tlsSecret: ""
  annotations: {}

probes:
  livenessProbeEnabled: false
  readinessProbeEnabled: false
  port: 8000
  endpoint: /v1/health

resources:
  enabled: false
  limits:
    cpu: 2000m
    memory: 2500Mi
  requests:
    cpu: 200m
    memory: 500Mi
